{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Consistency Training on CIFAR-10\n",
    "\n",
    "[![arXiv](https://img.shields.io/badge/arXiv-2310.14189-b31b1b.svg)](https://arxiv.org/abs/2310.14189)\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/leakedweights/mincy/blob/main/notebooks/ict_cifar.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "JAX & Flax implementation of [Improved Consistency Training](https://arxiv.org/abs/2310.14189)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch torchvision ipykernel einops wandb imageio\n",
    "%pip install --upgrade jax[tpu] jaxlib flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 64, channels: 256\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 32, channels: 128\n",
      "num groups: 48, channels: 192\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 16, channels: 64\n",
      "num groups: 24, channels: 96\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 8, channels: 32\n",
      "num groups: 12, channels: 48\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n",
      "num groups: 4, channels: 16\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from flax import linen as nn\n",
    "\n",
    "from mincy.models.unet import UNet\n",
    "\n",
    "cifar_config = {\"channel_mults\": (1, 2, 4, 8),\n",
    "     \"attention_mults\": (2,),\n",
    "     \"kernel_size\": (3,3),\n",
    "     \"dropout\": 0.1,\n",
    "     \"num_init_channels\": 16,\n",
    "     \"num_res_blocks\": 4,\n",
    "     \"pos_emb_type\": \"fourier\",\n",
    "     \"pos_emb_dim\": 16,\n",
    "     \"rescale_skip_conns\": True,\n",
    "     \"resblock_variant\":\"BigGAN++\",\n",
    "     \"fourier_scale\": 16,\n",
    "     \"nonlinearity\": nn.swish,}\n",
    "\n",
    "model = UNet(**cifar_config)\n",
    "\n",
    "key = random.key(0)\n",
    "img_shape = (32, 32, 3)\n",
    "batch_size = 64\n",
    "input_shape = (batch_size, *img_shape)\n",
    "\n",
    "init_image = jnp.ones(input_shape)\n",
    "init_t = jnp.ones((batch_size,))\n",
    "variables = model.init(key, init_image, init_t, train=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
